{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prs_test_for100.ipynb","provenance":[],"authorship_tag":"ABX9TyOKYTenCEA8+3AzjbVaD1WH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MimOKXWKCsMO","executionInfo":{"status":"ok","timestamp":1636206535407,"user_tz":-480,"elapsed":28747,"user":{"displayName":"mao yueyue","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11996306090384496990"}},"outputId":"c7b533ac-2251-494f-c1b7-668d7079981e"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\", force_remount=True)\n","import glob\n","import random\n","import os"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"9Amxzh0Xy_Qh"},"source":["###########################code  for test model accuracy########################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HvTMRhkCyEa","executionInfo":{"status":"ok","timestamp":1636206548282,"user_tz":-480,"elapsed":956,"user":{"displayName":"mao yueyue","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11996306090384496990"}},"outputId":"37271b59-0faf-4b63-dd4a-9fe530c570e9"},"source":["os.chdir(\"/content/gdrive/MyDrive/PRS_Project/testfor24\")\n","print(os.getcwd())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/199DtQ_vzsiRVohV5yNAclLbO1kCRzxWT/PRS_Project/testfor100\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59MtUpZyCyHQ","executionInfo":{"status":"ok","timestamp":1636206557640,"user_tz":-480,"elapsed":509,"user":{"displayName":"mao yueyue","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11996306090384496990"}},"outputId":"66d0cce0-4051-4e43-8fab-def4f2162de0"},"source":["#reading test dataset\n","video_filepaths1=[]\n","video_filepaths1=(glob.glob(\"processed_**.mp4\"))\n","print(len(video_filepaths1))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["937\n"]}]},{"cell_type":"code","metadata":{"id":"w35LU_dFCyJ_"},"source":["import cv2\n","import numpy as np\n","\n","labels1=[]\n","videos1=[]\n","\n","count=0\n","\n","for file in video_filepaths1:\n","    cap = cv2.VideoCapture(\"/content/gdrive/MyDrive/PRS_Project/testfor24/\"+file)\n","    nframe = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","    if nframe != 29:\n","      continue\n","    frames = [x for x in range(int(nframe))]\n","    framearray = []\n","    \n","\n","    for i in range(int(nframe)):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, frames[i])\n","        ret, frame = cap.read()\n","        frame = cv2.resize(frame, (64, 64))\n","        # framearray.append(cv2.cvtColor(np.array(frame), cv2.COLOR_BGR2GRAY))\n","        framearray.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n","\n","    cap.release()\n","    videos1.append(np.array(framearray)[:,:,:,np.newaxis])\n","\n","    filename=file.split(\"\\\\\")[-1]\n","    labels1.append(filename.split(\"_\")[1])\n","#     count+=1\n","#     if count > 10:\n","#         break\n","    \n","print(len(videos1))\n","print(len(labels1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AypQSj17CyMw"},"source":["# one hot encoding\n","from numpy import array\n","from numpy import argmax\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","# define example\n","values = array(labels2)\n","print(values)\n","# integer encode\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(values)\n","print(integer_encoded)\n","# binary encode\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","print(onehot_encoded)\n","# invert first example\n","inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n","print(inverted)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kp1GwzmCyPO"},"source":["import argparse\n","import os\n","\n","import matplotlib\n","matplotlib.use('AGG')\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.layers import (Activation, Conv3D, Dense, Dropout, Flatten,\n","                          MaxPooling3D)\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from keras.utils import np_utils\n","from keras.utils.vis_utils import plot_model\n","import sklearn.metrics as metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jA3_FWSwCyR2"},"source":["#test model structure\n","def createmodel():\n","  model = Sequential()\n","  model.add(Conv3D(64, kernel_size=(3, 3, 3), input_shape=(29, 64, 64, 1)))\n","  model.add(Activation('relu'))\n","  model.add(Conv3D(64, kernel_size=(3, 3, 3)))\n","  model.add(Activation('softmax'))\n","  model.add(AveragePooling3D(pool_size=(3, 3, 3)))\n","  model.add(Dropout(0.25))\n","\n","  model.add(Conv3D(128, kernel_size=(3, 3, 3)))\n","  model.add(Activation('relu'))\n","  model.add(Conv3D(128, kernel_size=(3, 3, 3)))\n","  model.add(Activation('softmax'))\n","  model.add(AveragePooling3D(pool_size=(3, 3, 3)))\n","  model.add(Dropout(0.25))\n","\n","  model.add(Flatten())\n","  model.add(Dense(512, activation='sigmoid'))\n","  model.add(Dropout(0.5))\n","  model.add(Dense(24, activation='softmax'))\n","\n","  model.compile(loss=categorical_crossentropy,\n","              optimizer=Adam(), metrics=['accuracy'])\n","  return model\n","\n","modeltest = createmodel()\n","modelgo = createmodel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hzeqonx7CyUt"},"source":["#load model weights and predict result for each test video\n","modeltest.load_weights(\"/content/gdrive/MyDrive/PRS_Project/model/model-improvement-24-0.74.hdf5\")\n","modeltest.compile(loss=categorical_crossentropy,optimizer=Adam(), metrics=['accuracy'])\n","predicts = modeltest.predict(np.array(videos2))\n","#24 words\n","labelname   = ['ABOUT','BECAUSE','COULD','DIFFERENT','UNDERSTAND','EVERYBODY','FOOTBALL','GOING','HUMAN','INFORMATION','KILLED','LEAVE','JUDGE','MEDIA','NUMBER','OUTSIDE','PERSON','QUESTION','VIOLENCE','SAYING','THERE','WHERE','YESTERDAY','REPORT']\n","                                                            \n","predout     = np.argmax(predicts,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eML_wO8zCyXo"},"source":["#confusion matrix\n","testout     = np.argmax(onehot_encoded,axis=1)\n","\n","testScores  = metrics.accuracy_score(testout,predout)                          \n","\n","print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n","print(metrics.classification_report(testout,\n","                                    predout,\n","                                    target_names=labelname,\n","                                    digits=4))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qR-mDKwlCyaU"},"source":["confusion   = metrics.confusion_matrix(testout,predout)\n","print(confusion)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afUJ8-a_y4Cq"},"source":["##################################code for visulization word############################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ihIKJLY-zWNp"},"source":["os.chdir(\"/content/gdrive/MyDrive/PRS_Project/visual_data\")\n","print(os.getcwd())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulswGr0wzW10"},"source":["video_filepaths_=[]\n","video_filepaths_=(glob.glob(\"processed_**.mp4\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zF1e9SdozW4W"},"source":["import cv2\n","import numpy as np\n","\n","labels_=[]\n","videos_=[]\n","\n","count=0\n","\n","for file in video_filepaths_:\n","    cap = cv2.VideoCapture(file)\n","    nframe = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","    # if nframe != 29:\n","    #   continue\n","    # print(nframe)\n","    frames = [x for x in range(int(nframe))]\n","    framearray = []\n","    \n","\n","    for i in range(int(nframe)):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, frames[i])\n","        ret, frame = cap.read()\n","        frame = cv2.resize(frame, (64, 64))\n","        # framearray.append(cv2.cvtColor(np.array(frame), cv2.COLOR_BGR2GRAY))\n","        framearray.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n","\n","    cap.release()\n","    videos_.append(np.array(framearray)[:,:,:,np.newaxis])\n","\n","    filename=file.split(\"\\\\\")[-1]\n","    labels_.append(filename.split(\"_\")[1])\n","#     count+=1\n","#     if count > 10:\n","#         break\n","    \n","print(len(videos_))\n","print(len(labels_))\n","print(labels_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8aT-auMzW7C"},"source":["# convert 24 words to one hot encoder\n","labels = ['ABOUT','BECAUSE','COULD','DIFFERENT','UNDERSTAND','EVERYBODY','FOOTBALL','GOING','HUMAN','INFORMATION','KILLED','LEAVE','JUDGE','MEDIA','NUMBER','OUTSIDE','PERSON','QUESTION','VIOLENCE','SAYING','THERE','WHERE','YESTERDAY','REPORT']\n","from numpy import array\n","from numpy import argmax\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","# define example\n","values = array(labels)\n","print(values)\n","# integer encode\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(values)\n","print(integer_encoded)\n","# binary encode\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","print(onehot_encoded)\n","# invert first example\n","inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n","print(inverted)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJiYfp8fyxV2"},"source":["#predict\n","modelgo.load_weights(\"/content/gdrive/MyDrive/PRS_Project/model/model-improvement-24-0.74.hdf5\")\n","modelgo.compile(loss=categorical_crossentropy,optimizer=Adam(), metrics=['accuracy'])\n","predicts = modelgo.predict(np.array(videos_))\n","\n","inverted = label_encoder.inverse_transform([argmax(predicts)])\n","print(inverted)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"co6K7pO105Kn"},"source":["#puttext \n","outpath = \"/content/gdrive/MyDrive/PRS_Project/visual_data/puttext/final_where_3.mp4\"\n","\n","vs = cv2.VideoCapture(\"/content/gdrive/MyDrive/PRS_Project/visual_data/processed_WHERE_3.mp4\")\n","writer = None\n","(W,H) = (None,None)\n","while True:\n","  (grabbed,frame) = vs.read()\n","  if not grabbed:\n","    print(\"Video not found\")\n","    break\n","  if W is None or H is None:\n","    (H,W) = frame.shape[:2]\n","\n"," # print(frame.shape)\n","  output = frame.copy()\n","  text = \"P: {}\".format(inverted)\n","\n","  cv2.putText(output,text,(10,40),cv2.FONT_HERSHEY_SIMPLEX,1.25,(0,255,0),5,cv2.LINE_AA)\n","\n","  if writer is None:\n","    print(\"Define writer\")\n","    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n","    writer = cv2.VideoWriter(outpath,fourcc,30,(W,H),True)\n","#  print(output.shape)\n","  writer.write(output)\n","writer.release()\n","vs.release()"],"execution_count":null,"outputs":[]}]}